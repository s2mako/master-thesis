{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "from pathlib import Path\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MALLET_PATH = r\"C:\\mallet\\bin\\mallet\"  # set to where your \"bin/mallet\" path is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tm_models_dir = Path(r\"C:\\Users\\martin\\git\\master-thesis\\6_models\")\n",
    "coherence_models_dir = Path(r\"C:\\Users\\martin\\git\\master-thesis\\7_evaluation\\gensim\\models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wdir = Path(\"../..\")\n",
    "\n",
    "coherence_models_dir = wdir.joinpath(\"7_evaluation\", \"gensim\", \"models\")\n",
    "corpusdir = wdir.joinpath(\"5_corpus\")\n",
    "evaluationdir = wdir.joinpath(\"6_evaluation\")\n",
    "coherencedir = wdir.joinpath(\"7_evaluation\", \"gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_tm(dictionary, corpus, topic_count, type=\"gensim\"):\n",
    "    if type == \"mallet\":\n",
    "        print(\"--Starting Topic Modeling (Mallet)...\")\n",
    "        return gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus, num_topics=topic_count,\n",
    "                                                id2word=dictionary)\n",
    "    elif type == \"gensim\":\n",
    "        print(\"--Starting Topic Modeling (Gensim)...\")\n",
    "        return LdaMulticore(corpus, num_topics=topic_count, id2word=dictionary, workers=11)\n",
    "\n",
    "\n",
    "def read_file(file):\n",
    "    docs = []\n",
    "    for l in file.open().readlines():\n",
    "        doc = l.split(\" \")\n",
    "        docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "\n",
    "def get_file_count(dir, name):\n",
    "    return str(sum(1 for f in dir.glob(name+\"*\")) + 1)\n",
    "\n",
    "\n",
    "def create_model_path(formatdir, overwrite):\n",
    "    if overwrite:\n",
    "        return formatdir.joinpath(f\"tm.bin\")\n",
    "    else:\n",
    "        count = get_file_count(formatdir, \"tm\")\n",
    "        return formatdir.joinpath(f\"tm_{count}.bin\")\n",
    "\n",
    "\n",
    "def save_tm_model(lda_model, filename, type, topic_count, format, overwrite=True):\n",
    "    format = filename.split(\"-\")[0]\n",
    "    # creating subfolders\n",
    "    modelsdir = evaluationdir.joinpath(\"models\", type)\n",
    "    segdir = modelsdir.joinpath(f\"seglen-{seglen}\")\n",
    "    topicsdir = segdir.joinpath(f\"topics-{topic_count}\")\n",
    "    topicsdir.mkdir(exist_ok=True, parents=True)\n",
    "    formatdir = topicsdir.joinpath(format)\n",
    "    formatdir.mkdir(exist_ok=True, parents=True)\n",
    "    # outfile path\n",
    "    outfile_model = create_model_path(formatdir, \"tm\", overwrite)\n",
    "    # write file\n",
    "    lda_model.save(str(outfile_model))\n",
    "    print(f\"--saved TM to: {outfile_model}\")\n",
    "\n",
    "\n",
    "def save_coherence_model(lda_model, texts, filename, type, measure):\n",
    "    coh_model = CoherenceModel(model=lda_model, texts=texts, coherence=measure)\n",
    "    format = filename.split(\"-\")[0]\n",
    "    # creating subfolders\n",
    "    modelsdir = evaluationdir.joinpath(\"models\", type)\n",
    "    segdir = modelsdir.joinpath(f\"seglen-{seglen}\")\n",
    "    topicsdir = segdir.joinpath(f\"topics-{topic_count}\")\n",
    "    formatdir = topicsdir.joinpath(format)\n",
    "    formatdir.mkdir(exist_ok=True, parents=True)\n",
    "    # outfile path\n",
    "    outfile_model = formatdir.joinpath(f\"coh-{measure.replace('_', '')}.bin\")\n",
    "    coh_model.save(str(outfile_model))\n",
    "    print(f\"--saved Coherence to: {outfile_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Mallet)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-c57de4d73e39>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"--Creating Doc2Bow\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[0mcorpus\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mdictionary\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdoc2bow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_update\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mdoc\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdocuments\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m     \u001B[0mlda_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_tm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdictionary\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcorpus\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtopic_count\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m     \u001B[0msave_tm_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlda_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstem\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtopic_count\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moverwrite\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moverwrite\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m     \u001B[1;31m# create coherence model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-6-6703a2d43d99>\u001B[0m in \u001B[0;36mcreate_tm\u001B[1;34m(dictionary, corpus, topic_count, type)\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"--Starting Topic Modeling (Mallet)...\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m         return gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus, num_topics=topic_count,\n\u001B[1;32m----> 5\u001B[1;33m                                                 id2word=dictionary)\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mtype\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"gensim\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"--Starting Topic Modeling (Gensim)...\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\miniconda3\\current\\envs\\gensimTesting\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001B[0m\n\u001B[0;32m    129\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom_seed\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrandom_seed\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    130\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcorpus\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 131\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcorpus\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    132\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    133\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfinferencer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\miniconda3\\current\\envs\\gensimTesting\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, corpus)\u001B[0m\n\u001B[0;32m    282\u001B[0m         \u001B[1;31m# NOTE \"--keep-sequence-bigrams\" / \"--use-ngrams true\" poorer results + runs out of memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    283\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"training MALLET LDA with %s\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcmd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 284\u001B[1;33m         \u001B[0mcheck_output\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcmd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshell\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    285\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword_topics\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_word_topics\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    286\u001B[0m         \u001B[1;31m# NOTE - we are still keeping the wordtopics variable to not break backward compatibility.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\miniconda3\\current\\envs\\gensimTesting\\lib\\site-packages\\gensim\\utils.py\u001B[0m in \u001B[0;36mcheck_output\u001B[1;34m(stdout, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m   1922\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"COMMAND: %s %s\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpopenargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1923\u001B[0m         \u001B[0mprocess\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msubprocess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstdout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstdout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mpopenargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1924\u001B[1;33m         \u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0munused_err\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprocess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcommunicate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1925\u001B[0m         \u001B[0mretcode\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprocess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1926\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mretcode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\scoop\\apps\\miniconda3\\current\\envs\\gensimTesting\\lib\\subprocess.py\u001B[0m in \u001B[0;36mcommunicate\u001B[1;34m(self, input, timeout)\u001B[0m\n\u001B[0;32m    949\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stdin_write\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    950\u001B[0m             \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstdout\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 951\u001B[1;33m                 \u001B[0mstdout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstdout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    952\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstdout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    953\u001B[0m             \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstderr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "type = \"mallet\"  # \"mallet\" | \"gensim\" | \"all\"\n",
    "seglen = 500\n",
    "topic_count = 60\n",
    "measure = \"c_v\"\n",
    "format = \"original\"\n",
    "overwrite = False\n",
    "# coherence graph\n",
    "create_coherence_graph = True\n",
    "\n",
    "corpus_files = corpusdir.glob(f\"seglen-{seglen}/*.txt\")\n",
    "\n",
    "corpus_files = Path(r\"C:\\Users\\martin\\git\\master-thesis\\5_corpus\\seglen-500\").glob(\"original*.txt\")\n",
    "\n",
    "for file in corpus_files:\n",
    "    print(\"File: \" + file.stem)\n",
    "    # splitting lines to docs\n",
    "    documents = read_file(file)\n",
    "    # build a dictionary\n",
    "    print(\"--Creating Dictionary\")\n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "    # Turns each document into a bag of words.\n",
    "    print(\"--Creating Doc2Bow\")\n",
    "    corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in documents]\n",
    "    lda_model = create_tm(dictionary, corpus, topic_count, type)\n",
    "    save_tm_model(lda_model, file.stem, type, topic_count, overwrite=overwrite)\n",
    "    # create coherence model\n",
    "    save_coherence_model(lda_model, documents, file.stem, type, measure, overwrite=overwrite)\n",
    "print(\"Finished Modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Single Topic Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type = \"mallet\"  # \"mallet\" | \"gensim\" | \"all\"\n",
    "seglen = 500\n",
    "topic_count = 60\n",
    "measure = \"c_v\"\n",
    "format = \"original\"\n",
    "overwrite = False\n",
    "# coherence graph\n",
    "create_coherence_graph = True\n",
    "\n",
    "corpus_files = corpusdir.glob(f\"seglen-{seglen}/*.txt\")\n",
    "\n",
    "corpus_files = Path(r\"C:\\Users\\martin\\git\\master-thesis\\5_corpus\\seglen-500\").glob(\"original*.txt\")\n",
    "\n",
    "for file in corpus_files:\n",
    "    print(\"File: \" + file.stem)\n",
    "    # splitting lines to docs\n",
    "    documents = read_file(file)\n",
    "    # build a dictionary\n",
    "    print(\"--Creating Dictionary\")\n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "    # Turns each document into a bag of words.\n",
    "    print(\"--Creating Doc2Bow\")\n",
    "    corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in documents]\n",
    "    lda_model = create_tm(dictionary, corpus, topic_count, type)\n",
    "    save_tm_model(lda_model, file.stem, type, topic_count, overwrite=overwrite)\n",
    "    # create coherence model\n",
    "    save_coherence_model(lda_model, documents, file.stem, type, measure, overwrite=overwrite)\n",
    "print(\"Finished Modeling\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Coherence Variance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def coherence_variance(file, iteration, topic_count, measure, type):\n",
    "    print(\"File: \" + file.stem)\n",
    "    # splitting lines to docs\n",
    "    documents = read_file(file)\n",
    "    # build a dictionary\n",
    "    print(\"--Creating Dictionary\")\n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "    # Turns each document into a bag of words.\n",
    "    print(\"--Creating Doc2Bow\")\n",
    "    corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in documents]\n",
    "    lda_model = create_tm(dictionary, corpus, topic_count, type)\n",
    "    # write file\n",
    "    tmfile  = r\"C:\\Users\\martin\\git\\master-thesis\\6_evaluation\\coherence-variance\\gensim\\tm_\" + str(iteration) + \".bin\"\n",
    "    lda_model.save(tmfile)\n",
    "    # create coherence model\n",
    "    cohfile = r\"C:\\Users\\martin\\git\\master-thesis\\6_evaluation\\coherence-variance\\gensim\\coh_\" + str(iteration) + \".bin\"\n",
    "    coh_model = CoherenceModel(model=lda_model, texts=documents, coherence=measure)\n",
    "    coh_model.save(cohfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  1\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  2\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  3\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  4\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  5\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  6\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  7\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  8\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n",
      "Iteration:  9\n",
      "File: original-500\n",
      "--Creating Dictionary\n",
      "--Creating Doc2Bow\n",
      "--Starting Topic Modeling (Gensim)...\n"
     ]
    }
   ],
   "source": [
    "type = \"gensim\"  # \"mallet\" | \"gensim\" | \"all\"\n",
    "seglen = 500\n",
    "topic_count = 60\n",
    "measure = \"c_v\"\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(\"Iteration: \", i)\n",
    "    coherence_variance(Path(r\"C:\\Users\\martin\\git\\master-thesis\\5_corpus\\seglen-500\\original-500.txt\"), i, topic_count, measure, type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = Path(r\"C:\\Users\\martin\\git\\master-thesis\\6_evaluation\\coherence-variance\")\n",
    "coh_models = {}\n",
    "for file in path.glob(\"coh*.bin\"):\n",
    "    print(file.stem)\n",
    "    coh_models.update({file.stem: CoherenceModel.load(str(file))})\n",
    "print(\"finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coh_models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multiple Coherences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coherence_graph(type, texts, start, limit, step):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    # build a dictionary\n",
    "    print(\"--Creating Dictionary\")\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    # Turns each document into a bag of words.\n",
    "    print(\"--Creating Doc2Bow\")\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "    print(\"Creating coherence Graph...\")\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = create_tm(dictionary=dictionary, corpus=corpus, type=type, topic_count=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    # Show graph\n",
    "    x = range(start, limit, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # Print the coherence scores\n",
    "    for m, cv in zip(x, coherence_values):\n",
    "        print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n",
    "\n",
    "\n",
    "start = 200\n",
    "limit = 300\n",
    "step = 10\n",
    "\n",
    "corpus_files = Path(r\"C:\\Users\\martin\\git\\master-thesis\\5_corpus\\test\")\n",
    "\n",
    "\n",
    "for file in corpus_files.glob(\"*.txt\"):\n",
    "    print(\"File: \" + file.stem)\n",
    "    # splitting lines to docs\n",
    "    texts = read_file(file)\n",
    "    compute_coherence_graph(type=type, texts=texts, start=start,\n",
    "                            limit=limit, step=step)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensimTesting",
   "language": "python",
   "name": "gensimtesting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}